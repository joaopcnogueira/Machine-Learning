{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstração do uso de pipelines no scikit-learn com o dataset do Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código no estilo de programação procedural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8342696629213483\n",
      "Test score: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# lendo o dataset\n",
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "# retirando as colunas Nome, Ticket e Cabin\n",
    "df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n",
    "\n",
    "# dividindo em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['Survived'], axis=1), \n",
    "                                                    df['Survived'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# tratando variáveis categóricas com o one-hot-encoding\n",
    "X_train_new = pd.get_dummies(X_train)\n",
    "X_test_new = pd.get_dummies(X_test)\n",
    "\n",
    "# tratando valores nulos na coluna Age\n",
    "mean_age = X_train_new['Age'].mean()\n",
    "X_train_new['Age'].fillna(mean_age, inplace=True)\n",
    "X_test_new['Age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "# tratando valores nulos na coluna Fare\n",
    "mean_fare = X_train_new['Fare'].mean()\n",
    "X_train_new['Fare'].fillna(mean_fare, inplace=True)\n",
    "X_test_new['Fare'].fillna(mean_fare, inplace=True)\n",
    "\n",
    "# treinando o modelo: árvore de decisão\n",
    "tree = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "tree.fit(X_train_new, y_train)\n",
    "\n",
    "# avaliando o modelo\n",
    "train_score = tree.score(X_train_new, y_train)\n",
    "test_score = tree.score(X_test_new, y_test)\n",
    "print(\"Train score: {}\".format(train_score))\n",
    "print(\"Test score: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8342696629213483\n",
      "Test score: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "\n",
    "# lendo o dataset\n",
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "# retirando colunas com nome, ingresso e cabine dos conjuntos\n",
    "df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n",
    "\n",
    "# dividindo em conjunto de treino e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['Survived'], axis=1), \n",
    "                                                    df['Survived'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "model = Pipeline(steps=[\n",
    "    ('one-hot encoder', OneHotEncoder()),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(\"Train score: {}\".format(train_score))\n",
    "print(\"Test score: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline + Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.815956 (0.024300)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# lendo o dataset\n",
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "# retirando colunas com nome, ingresso e cabine dos conjuntos\n",
    "df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('one-hot encoder', OneHotEncoder()),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))\n",
    "])\n",
    "\n",
    "# validando o modelo usando 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = cross_validate(model, X=df.drop(['Survived'], axis=1), y=df['Survived'], cv=kfold, return_estimator=True)\n",
    "print(\"Average accuracy: %f (%f)\" %(results['test_score'].mean(), results['test_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.04860263, 0.05019822, 0.04559975]),\n",
       " 'std_fit_time': array([0.0020585 , 0.00147057, 0.00338091]),\n",
       " 'mean_score_time': array([0.01360025, 0.01340199, 0.01159973]),\n",
       " 'std_score_time': array([0.00049   , 0.00049184, 0.00149645]),\n",
       " 'param_tree__max_depth': masked_array(data=[3, 4, 5],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'tree__max_depth': 3},\n",
       "  {'tree__max_depth': 4},\n",
       "  {'tree__max_depth': 5}],\n",
       " 'split0_test_score': array([0.79888268, 0.79888268, 0.79888268]),\n",
       " 'split1_test_score': array([0.79775281, 0.79775281, 0.78651685]),\n",
       " 'split2_test_score': array([0.85955056, 0.8258427 , 0.81460674]),\n",
       " 'split3_test_score': array([0.79775281, 0.79775281, 0.7752809 ]),\n",
       " 'split4_test_score': array([0.8258427 , 0.8258427 , 0.81460674]),\n",
       " 'mean_test_score': array([0.81593715, 0.80920314, 0.7979798 ]),\n",
       " 'std_test_score': array([0.02429306, 0.01357972, 0.01548562]),\n",
       " 'rank_test_score': array([1, 2, 3]),\n",
       " 'split0_train_score': array([0.83426966, 0.83707865, 0.85955056]),\n",
       " 'split1_train_score': array([0.82889201, 0.8401122 , 0.85413745]),\n",
       " 'split2_train_score': array([0.80224404, 0.83029453, 0.85273492]),\n",
       " 'split3_train_score': array([0.83730715, 0.84712482, 0.85553997]),\n",
       " 'split4_train_score': array([0.82608696, 0.83169705, 0.85553997]),\n",
       " 'mean_train_score': array([0.82575996, 0.83726145, 0.85550058]),\n",
       " 'std_train_score': array([0.01239893, 0.00608189, 0.00227651])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# lendo o dataset\n",
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "# retirando colunas com nome, ingresso e cabine dos conjuntos\n",
    "df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n",
    "\n",
    "# criando o modelo usando pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('one-hot encoder', OneHotEncoder()),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))\n",
    "])\n",
    "\n",
    "# Tunando hiperparâmetros com 5-fold cross-validation e pipelines\n",
    "parameters = {'tree__max_depth': [3, 4, 5]}\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(model, param_grid=parameters, cv=kfold, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X=df.drop(['Survived'], axis=1), y=df['Survived'])\n",
    "\n",
    "# qual o melhor parâmetro\n",
    "grid.best_params_ \n",
    "# OUTPUT\n",
    "# {'tree__max_depth': 3}\n",
    "\n",
    "# para ver os resultados do hyperparameter tunning + cross-validation\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill...\n",
       "                                                               max_features=None,\n",
       "                                                               max_leaf_nodes=None,\n",
       "                                                               min_impurity_decrease=0.0,\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               presort=False,\n",
       "                                                               random_state=0,\n",
       "                                                               splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1, param_grid={'tree__max_depth': [3, 4, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# lendo o dataset\n",
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "# retirando colunas com nome, ingresso e cabine dos conjuntos\n",
    "df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# pipeline para pré-processamento das variáveis Age e Fare\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# pipeline para pré-processamento das variáveis Sex e Embarked\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('one-hot encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Compondo os pré-processadores\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, ['Age', 'Fare']),\n",
    "    ('cat', cat_transformer, ['Sex', 'Embarked'])\n",
    "])\n",
    "\n",
    "\n",
    "# criando o modelo usando pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('tree', DecisionTreeClassifier(max_depth=3, random_state=0))\n",
    "])\n",
    "\n",
    "\n",
    "# Tunando hiperparâmetros com 5-fold cross-validation e pipelines\n",
    "parameters = {'tree__max_depth': [3, 4, 5]}\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(model, param_grid=parameters, cv=kfold, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X=df.drop(['Survived'], axis=1), y=df['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
